# Papers to checkout 
Before diving into the code, i suggest you to checkout the following papers:

1. Attention is all you need 
2. BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension

Both are very good papers and will help you understand the concepts covered in this repo, find the papers in this folder.